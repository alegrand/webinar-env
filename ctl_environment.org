#+TITLE: Controlling Your Environment
#+AUTHOR: Cristian Ruiz, Michael Mercier\newline INRIA - France
#+DATE: April 5, 2016 -- Reproducible Research Webinar \mylogos
#+STARTUP: beamer overview indent

#+OPTIONS: H:2 toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+LaTeX_CLASS_OPTIONS: [11pt,xcolor=dvipsnames,presentation]
#+BEAMER_COLOR_THEME:
#+BEAMER_FONT_THEME:
#+BEAMER_HEADER:
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+BEAMER_INNER_THEME:
#+BEAMER_OUTER_THEME:
#+BEAMER_THEME: default
#+LATEX_CLASS: beamer

#+LATEX_HEADER: \PassOptionsToPackage{svgnames}{xcolor}
#+LATEX_HEADER: \let\AtBeginDocumentSav=\AtBeginDocument
#+LATEX_HEADER: \def\AtBeginDocument#1{}
#+LATEX_HEADER: \input{org-babel-style-preembule.tex}
#+LATEX_HEADER: \let\AtBeginDocument=\AtBeginDocumentSav
#+LATEX_HEADER: \usepackage{minted}

#+LATEX_HEADER: %\let\tmptableofcontents=\tableofcontents
#+LATEX_HEADER: %\def\tableofcontents{}
#+LATEX_HEADER:  \usepackage{color,soul}
#+LATEX_HEADER:  \definecolor{lightblue}{rgb}{1,.9,.7}
#+LATEX_HEADER:  \sethlcolor{lightblue}
#+LATEX_HEADER:  \let\hrefold=\href
#+LATEX_HEADER:  \renewcommand{\href}[2]{\hrefold{#1}{\SoulColor\hl{#2}}}
#+LATEX_HEADER: \newcommand{\muuline}[1]{\SoulColor\hl{#1}}
#+LATEX_HEADER: \makeatletter
#+LATEX_HEADER: \newcommand\SoulColor{%
#+LATEX_HEADER:   \let\set@color\beamerorig@set@color
#+LATEX_HEADER:   \let\reset@color\beamerorig@reset@color}
#+LATEX_HEADER: \makeatother

#+BIND: org-latex-title-command ""



#+LATEX_HEADER: \def\mylogos{\\\vspace{1cm}\begin{center}\includegraphics[height=1.2cm]{logos/inr_logo_sans_sign_coul.png}\hspace{0.5cm}\insertlogo{\includegraphics[height=1.2cm]{logos/grid5000.png}}\hspace{0.5cm}\end{center}\vspace{-1cm}}


#+LaTeX: \input{org-babel-document-preembule.tex}

* setup								   :noexport:

** Download beamer theme and logos

#+BEGIN_SRC sh
 mkdir theme
 wget https://raw.githubusercontent.com/camilo1729/latex-tools/master/beamer_theme/beamerthemeCristian.sty
 mv beamerthemeCristian.sty  theme/
 wget https://github.com/camilo1729/latex-tools/blob/master/logos/grid5000.png
 wget https://github.com/camilo1729/latex-tools/blob/master/logos/inr_logo_sans_sign_coul.png
 mkdir logos
 mv *.png logos
#+END_SRC



* Intro
#+BEGIN_LaTeX
\AtBeginSection[]
  {
     \begin{frame}<beamer>
     \frametitle{Outline}
     \tableofcontents[currentsection]
     \end{frame}
  }
#+END_LaTex

** People involved

- Michael Mercier
- Cristian Ruiz
- Salem Harrache


- Olivier Richard
- Pierre Neyron
- Lucas Nussbaum
- Arnaud Legrand

* Why is it necessary?
** Motivations

  Reproducible research: What does it mean?

  Need a reminder: See the [[http://newstream.imag.fr/2016-03-07_Reproducible-Research_Arnaud-legrand.mp4][first webinar]]

#+BEGIN_LaTeX
\begin{block}{Definition}
 A way to encapsulate all aspects of our in silico analysis in a manner that 
would facilitate independent replication by another scientist
\end{block}
#+END_LaTeX

  *Reproducibility is a cornerstone of scientific method*

** Problem statement
Experiment replication is not an easy task if you do not have it in mind from the
beginning:
\vspace{0.2cm}

#+BEGIN_QUOTE
The path from having a piece of software running on the programmer's own machine
to getting it running on someone else's machine is fraught with potential pitfalls
#+END_QUOTE

#+BEGIN_LaTeX
  \bottomcite{Philip J. Guo and Dawson Engler,
     \href{http://www.pgbovine.net/publications/CDE-create-portable-Linux-packages-short-paper_USENIX-2011.pdf}
    {\textit{CDE: Using System Call Interposition to Automatically Create Portable Software Packages}},
    USENIX LISA Conference,2011}
#+END_LaTeX

For reproducible research the scientist provides for both experiment and
   analysis:
  - All the artifacts (input/outputs files)
  - The source code
  - Documentation on how to compile, install and run

Still, several problems may prevent someone to rerun an experiment

** Is code sufficient? 
#+BEGIN_QUOTE
An article about computational science in a scientific publication
is not the scholarship itself, it is merely advertising of the scholarship.
The actual scholarship is *the complete software development environment* and 
the complete set of instruction which generated the figures.
David Donoho, 1998
#+END_QUOTE
  
** Dependencies and compilation problems

*Unresolved dependencies:*
#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
  \includegraphics[scale=0.25]{figures/Dependency.png}
  \label{fig:s}
\end{figure}
#+END_LaTeX

*Compilation errors:*
#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
  \includegraphics[scale=0.25]{figures/Compilation_error.png}
  \label{fig:s}
\end{figure}

  \bottomcite{Collberg, Christian \textit{et Al.},
     \href{http://reproducibility.cs.arizona.edu/v2/RepeatabilityTR.pdf}{\textit{Measuring Reproducibility in Computer Systems Research}},
    \url{http://reproducibility.cs.arizona.edu/}\qquad 2014,2015}
#+END_LaTeX

Less than 50% of experimental setups of papers submitted ACM conferences and journals can be built.

** Other technical issues
- Imprecise documentation: \\
  "/I have no clue about how to install it, configure it or run it!/"

- Dependency Hell: \\
  "/I can't install this dependency package without breaking my entire system/"
- Code rote: \\
  "/This dependency package version is buggy! What was the version that was used to run the experiment in the first place?!?/"

#+BEGIN_LaTeX
  \bottomcite{Carl Boettiger,
     \href{http://www.carlboettiger.info/assets/files/pubs/10.1145/2723872.2723882.pdf}{\textit{An introduction to Docker for reproducible research}},
    ACM SIGOPS Operating Systems Review,2015}
#+END_LaTeX

** Cultural challenges

- Efforts are not rewarded by the current academic research and funding environment
- Software vendors tend to protect their markets through proprietary formats and interfaces
- Investigators naturally tend to want to own and control their research tools
- Even the most generalized software will not be able to meet the needs of every researcher in a field
- The need to derive and publish results as quickly as possible precludes the often slower standards-based development path

#+BEGIN_LaTeX
  \bottomcite{J. T. Dudley and A. J. Butte,
     \href{http://www.nature.com/nbt/journal/v28/n11/pdf/nbt1110-1181.pdf}{\textit{In silico research in the era of cloud computing}},
    \url{Nature Biotechnology}\qquad 2010}
#+END_LaTeX

** Distributing software possibility

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.4]{figures/CDE_author_user.pdf}
\end{figure}
#+END_LaTeX

** Disseminating science software

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.7]{figures/virtual_appliances.pdf}
\end{figure}
#+END_LaTeX
   
** Controlling your environment

- One way to go is to take care of your experimental environment

- You have several options:
   - Use a constrained environment
   - Capture your environment
   - Build your environment

*** Constraint for simplicity, complexity for freedom
Each of them have different levels of constraint and flexibility:
    - The more constrained your environment is, the more simple it is 
    - Freedom comes with responsibility

** Why should I take care of my experiment environment
For myself:
  - Be able to reproduce my own experiment later
  - Be able to scale my experiment on other machines
  - Facilitate experiment extensions and modifications
  - Be a better scientist by doing better science :)

For other people: my students, my colleagues, my peers, \dots
  - Allow them to reproduce my experiment and corroborate (or not) my results
  - Allow them to base their research on my research

For everybody:
  - Improve knowledge sharing
  - Increase collaboration possibilities
  - Do better science!

* What is an environment?
** Environment definition
#+BEGIN_LaTeX
\begin{block}{Definition}
   In our case:
   An environment is a set of tools and materials that permit a complete
   reproducibility of a part or the whole experiment process.
\end{block}
#+END_LaTeX

   TODO: Add a schema with an experiment workflow

   Can be numerous or unique depending on the experiment workflow:
   - Experiment runtime environments
     - local, on a testbed, on a dedicated server,\dots
   - Analysis runtime environments
     - Usually a unique local environment

   Whole environment contains hardware and software information

** Hardware
Necessary when we carry out performance measures

Tools to capture hardware configuration:
  - =dmidecode=
  - hwloc (=lstopo=)
  - ls* tools (lsblk, lshw, lspci, lsmod,\dots)
  - proprietary tools (bios, nvidia,\dots)
  - Testbeds hardware description API (Grid'5000, Chameleon)

*** The hardware is not shareable
    As it is no shareable the hardware environment needs to be documented
    as exhaustively as possible. Of course it depends on how the results 
    of an experiment are affected by the underlying hardware.

** Software

Different types of environment:
*** Very succinct (usually what is provided, if provided...)                                      :B_definition:
:PROPERTIES:
:BEAMER_env: alertblock
:END:
A minimal description in mail or a README in a git repository

*** Partial
:PROPERTIES:
:BEAMER_env: definition
:END:
A bundle of the experiment tool and it dependencies. It is generally limited
to one language runtime(Pyton, Ruby, Java, \dots)
*** Full
:PROPERTIES:
:BEAMER_env: example
:END:
A complete environment backup with the operating system included
- Virtual machine (VirtualBox, Qemu/KVM, VMware,\dots)
- Kadeploy image tarball (Grid'5000) 
  # It should be disk image, it is too G5K specific
- Linux container tarball (docker, LXC, rkt,\dots) 
  # I dont know about this one for me it is not full. 
  # It does not contain the kernel. It is more like partial 


** Types of environments

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.6]{figures/types_of_environments.pdf}
\end{figure}
#+END_LaTeX

** Software Appliances
*** Advantage 							    :B_block:
    :PROPERTIES:
    :BEAMER_env: block
    :END:

keep everything together:
#+BEGIN_CENTER
OS + configuration + application
#+END_CENTER

*** Some facts							    :B_block:
    :PROPERTIES:
    :BEAMER_env: block
    :END:
- Availability of Testbeds such as Grid'5000, Chameleon, Cloudlab, etc
- Ubiquity of Cloud computing infrastructures.
- Virtualization accessible to almost everyone that has a computer with modest requirements.



* Use a constraint environment
** Use of third party environments

Environment build, specialized, controlled, versioned by somebody else:

#+BEGIN_LaTeX
  \bottomcite{Brammer, Grant R \textit{et Al.},
     \href{http://www.sciencedirect.com/science/article/pii/S187705091100127X}
{\textit{Paper M\^ach\'e: Creating Dynamic Reproducible Science.}},
    \url{International Conference on Computational Science}, ICSS 2011}
#+END_LaTeX

- Activepapers (Beta)
  - Python or JVM based language
- SageMathCloud
  - Use Jupyter
    - Julia, Python, R, Haskell, Ruby...
    - 40 languages (partly) supported
- Default Testbed (Grid'5000, Cloudlab, Chameleon) environments 
- Software appliances market place (e.g., TURNEKY[fn:turnkey], Cloud Market[fn:amazon]) 

Sharing is easy but you have to stick to what the environment provides

[fn:turnkey] http://www.turnkeylinux.org
[fn:amazon] http://www.thecloudmarket.com

** Use a virtual environment as a base

Start your experimental setup in a virtual environment *from the beginning*
- Virtual Machines:
  - VirtualBox
  - Qemu/KVM
  - VMware player

- Linux containers:
  - Docker
  - LXC
  - rkt

*** Advantages
    :PROPERTIES:
    :BEAMER_env: example
    :END:
  - Your environment is controlled (you start from a clean system)
  - Easy backup using snapshot capabilities

*** Drawbacks
  - Not easy to share (except with Vagrant or Docker repository)
  - *You don't know what is inside the box :(*

* Capturing an environment
** Capturing an environment
   Several approaches for capturing your environment:
   - export everything:
     - OS + Lib + App
   - capture only what is needed to run on a similar system:
     - App + dependencies

** Copying your experiment environment
   A simple capture of an environment is a *complete copy* of it.

   It depends on what your environment is:
   - On a classical local machine:
     - Problem: A simple backup bundle is not easily usable by others
     - Partial solution: Clone your hard drive to a VM (excluding personal data)

   - On a VM or any Copy-on-write environment use the instant
       snapshot capability
     - Faster and simpler backup
     - VM need to be used from the beginning (mentioned previously)

   - On a testbed machine use the provided snapshot mechanism

   In either case *sharing is complicated*
     - Huge environment images of several Gigabytes are common
     - Need a dedicated place to store them (a repository or some market place)

  *You still don't know what is inside the box :(*

#+BEGIN_LaTeX
  \bottomcite{J. T. Dudley and A. J. Butte,
     \href{http://www.nature.com/nbt/journal/v28/n11/pdf/nbt1110-1181.pdf}{\textit{In silico research in the era of cloud computing}},
    \url{Nature Biotechnology}\qquad 2010}
#+END_LaTeX

** Capture only what is needed
Use a tracking tool to *capture only what is necessary*

Instrumenting a run of your experiment to catch every used material:
   - Binaries/Scripts (experiment.py, Python 2.7)
   - Configuration files (conf.yaml)
   - Libraries (libc, numpy, matplotlib)
   $\leadsto$ Create a compress bundle

Rerun the experiment on another machine:
   1) Import the provided bundle
   2) Initialize the environment (depends on the tools...)
   3) Rerun the exact same experiment

Capture is not foolproof:
   - Running with only one set of parameters is not enough
   - If something is missing $\leadsto$ you have to add it by hand

Less messy than virtual environment copy
but *it is not easy to modify it* to extend an experiment


** Capture tools

Existing tools:
- [[http://www.pgbovine.net/cde.html][CDE]] (Guo et al., 2011)
  - not maintained since 2013 but it was the first to bring the idea
- *[[https://vida-nyu.github.io/reprozip/][ReproZip]]* (Freire et al., 2013)
  - Well supported
  - one tool to trace and pack
  - several tools to unpack and run (install package, chroot, docker,
    vagrant)
  - More during the demo :)
- [[http://reproducible.io/][CARE]] (Janin et al., 2014)
  - Seems a bit rough! (only a text file as doc)
  - unmaintained since 2014
- Parrot
  - See this interesting paper [[http://ccl.cse.nd.edu/research/papers/techniques-ipres-2015.pdf][Preserve the Mess or Encourage Cleanliness?]] (Thain et al., 2015)
  - Limited to the Parrot filesystem...

* Building the entire environment

** Environment generation
- If you're moving a computation to a new system, 
  it should be simple and straightforward to set up the environment almost identical 
  to that of the original machine
- A major challenge in reproducing computations is installing the prerequisite
  software environment
- Modern open computational science relies on complex software stacks
- So, it is necessary to know:
   - How it was built
   - What does it contains
   - How can I modify it to extend the experiment


** How software is installed and configured?

*** Source code compilation:
 
  #+BEGIN_SRC sh
   $ tar -xzf pdt-3.19.tar.gz && cd pdtoolkit-3.19/
   $./configure -prefix=/usr/local/pdt-install
   $ make clean install
  #+END_SRC
- Need to install all dependencies by hand
- Some skills are required
*** Package manager:  
is a collection of software tools that *automates* the process of *installing*, 
*upgrading*, *configuring*, and *removing* computer programs 
for a computer's operating system in a consistent manner

- Examples in the Linux world: APT, yum, pacman, Nix \dots 

- There exists as well package mangers for programming languages: 
  Bundler, CPAN, CRAN, EasyInstall, Go Get, Maven, pip, RubyGems, etc


** DevOps approach

- Dev = Development, Ops= (System) operation
- You have a pile of crusty code that's hard to install
- It's hard to document how to install it
- Why not develop scripts that reliably install your toolset?
  - Because that sounds hard ?
  - but it's more fun than writing documentation

- Use all the good things that software engineering has created along decades for ensuring isolation and reproductibility
** Creating recipes: text based description

- README
- Shell scripts 
- Configuration management tools: 
  automate software configuration and installation
  - Software stacks can be easily transportable
  - Some CM tools: Puppet, Salt, Ansible
  - A lot of work have to be done to write recipes \frowny 


** DevOps response: Docker 

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.3]{figures/eliminates-matrix-from-hell.png}
\end{figure}
#+END_LaTeX

Any application can be easily moved through different environments 

** DevOps response: Docker 

- Docker is an open-source engine that automates the deployment
  of any application as a lightweight, portable, self-sufficient container
  that will run virtually anywhere

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.1]{figures/docker-vm-container.png}
\end{figure}
#+END_LaTeX

- Docker works with images that consume minimal disk space, versioned, archiveable, and shareable

- Docker tries to achieve deterministic builds by isolating your service, 
  building it from a snapshotted OS and running imperative steps on top of it.
** DevOps response: Vagrant

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.3]{figures/vagrant_explained.pdf}
\end{figure}
#+END_LaTeX

- It automates the build of development environment using a base environment called *box* and 
  a series of text-based instructions
 
** DevOps response: Vagrant
   
- Researchers write text-based configuration files that provide instruction to build virtual machines
- *Solves in some way the problem of sharing a VM* as these files are small 
  researchers can share them easily and track different versions via
  source-control repositories
- *VMs are not seen as black boxes anymore*
- Researchers can automate the process of building and configuring virtual machines
- It is possible to use different providers: EC2, Virtualbox, VMware, Docker, etc \dots

** Reproducible builds: a functional package management (Nix)

- The principle: *two independent runs of a given build process for a given set of inputs should return the same value*
- Functional hash-based immutable package management
- Isolated build
- Deterministic
- No dependency hell

** Reproducible builds: Nix workflow

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.7]{figures/Nix_workflow.pdf}
\end{figure}
#+END_LaTeX

** Environment generation
#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.6]{figures/Environment_creation.pdf}
\end{figure}
#+END_LaTeX



** Reconstrucability
#+BEGIN_LaTeX
An experimental setup \(E'\) is reconstructable if the following three facts hold:
\begin{itemize}
\item Experimenters have access to the original base experimental setup \(E\).
\item Experimenters know exactly the sequence of actions \\* \(\langle A_{1}, A_{2}, A_{3}, ..., A_{n}\rangle \) that produced \(E'\).
\item {\bf Experimenters are able to change some action \(A_{i}\) and successfully re-construct an experimental setup \(E''\)}.
\end{itemize}
#+END_LaTeX


** Reconstrucability
#+BEGIN_LaTeX

It can be expressed as \(E' = f(E,\langle A_{i} \rangle ) \)
where \( f \) applies \(\langle A_{i} \rangle \) to \(E\) to
derive the experimental setup \(E'\).


Few cases where this hypothesis does not hold:
\begin{itemize}
  \item An action \(A_{i}\) is composed of sub-tasks that are executed concurrently making the process not deterministic.
        For example: \texttt{Makefile} \texttt{-j}
  \item (\emph{Debian 8}) is validated based on timestamps
  \item Leaked information from the host: \texttt{hostname},\texttt{/proc/cpuinfo}
\end{itemize}

Additionally problems:
\begin{itemize}
\item Accessing the same base setup \(E\)
\item {\bf Software used is not available anymore}
\item {\bf Specific version of packages cannot be installed}
\end{itemize}

#+END_LaTeX



** Dealing with software availability (Debian Snapshot)
- It's an archive that allows access to old packages based on dates and version numbers
- It provides a valuable resource for tracking down when regressions were introduced, 
  or *for providing a specific environment that a particular application may require to run*
- Only concerns software that is packaged \frowny 

** Kameleon: Reconstructable Appliance Generator 

#+BEGIN_LaTeX
\begin{figure}[!h]
  \center
\includegraphics[scale=0.6]{figures/Kameleon_explained.pdf}
\end{figure}
#+END_LaTeX
** Kameleon Features
- Easy to use  $\leadsto$ structured language based on few constructs and 
  which relies on shell commands 
- Allows shareability thanks to the hierarchical structure of recipes and the extend 
  mechanism 
- Kameleon supports the build process by providing debugging mechanisms such as interactive shell sessions, 
  break-points and checkpointing. 
- Allows the easy integration of providers using the same language for the recipes. 
- *Persistent cache makes possible reconstructability*

** notes							   :noexport:
I can introduce the definition of reconstructability
      Quelles bonnes propriétés sont elles recherchée?

      Quelles sont les étapes:
      1. Partir de 0
      2. S'assurer qu'on peut reconstruire à chaque instant
      3. Distribuer

      Note: çà veut dire quoi partir de 0 ?
      1. Partir d'une image préexistante considérée comme stable. Avec
         l'effort des reproducible build de debian, c'est pas mal
         (mentionner aussi debian snapshot)
	 - Script, Outils des distributions, VM et container, docker file, vagrant
	 - Nix / Guix
	 - Kameleon
      2. Construire complètement from scratch (même l'OS)
	 - Kameleon


* Comment utiliser un environnement?                               :noexport:



** notes
      C'est transverse, comme "comment distribuer" donc à expliquer au
      fur et à mesure
      - VM, container, chroot, bundle python, hdf5 + \dots, \dots
      Faire un petit tableau récapitulatif
* Demo time
** Reprozip
      1. Reprozip (capture) (les autres ayant l'air plus ou moins maintenus)
** Docker
Docker advantages for reproducible research:

- Integrating into local development environments
- Modular reuse
- Portable environments
- Public repositories for sharing
- Versioning

#+BEGIN_LaTeX
  \bottomcite{Carl Boettiger,
     \href{http://www.carlboettiger.info/assets/files/pubs/10.1145/2723872.2723882.pdf}{\textit{An introduction to Docker for reproducible research}},
    ACM SIGOPS Operating Systems Review,2015}
#+END_LaTeX

** Docker advantages

- Portable computation & sharing

#+BEGIN_SRC sh
 $ docker export container-name > container.tar
 $ docker push username/r-recommended
#+END_SRC

- Re-usable modules
#+BEGIN_SRC sh
$ docker run -d --name db training/postgres
$ docker run -d -P --link db:bd training/webapp \
   python app.py
#+END_SRC

- Versioning

#+BEGIN_SRC sh
$ docker history r-base
$ docker tag  d7e5801bb7ac ttimbers/mmp-dyf-skat:latest
#+END_SRC



** Kameleon
      3. Kameleon / example Batsim ?
	 - Success story: un an après, ça marche encore!


* Emacs Setup                                                      :noexport:                                                                                                   
This document has local variables in its postembule, which should
allow org-mode to work seamlessly without any setup. If you're
uncomfortable using such variables, you can safely ignore them at
startup. Exporting may require that you copy them in your .emacs.

# Local Variables:
# eval:    (setq org-latex-listings 'minted)
# eval:    (setq org-latex-minted-options '(("bgcolor" "Apricot") ("numbersep" "5pt")))
# eval:    (setq org-latex-pdf-process '("pdflatex -shell-escape -interaction nonstopmode -output-directory %o %f"))
# End:
